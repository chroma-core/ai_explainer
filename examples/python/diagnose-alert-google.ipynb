{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Dev Explainer - AI is stateless\n",
    "\n",
    "This is a notebook for https://www.aiexplainer.dev/stateless\n",
    "\n",
    "View all notebooks at https://github.com/chroma-core/ai_explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an API Key from Google AI Studio\n",
    "1. Go to Google AI Studio: https://makersuite.google.com/\n",
    "2. Click on 'Get API key' in the left sidebar\n",
    "3. Create a new API key or use an existing one\n",
    "4. Replace `<your_api_key>` below with your actual API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code\n",
    "In Colab - you can click, \"Runtime\" -> \"Run All\" in the topbar\n",
    "\n",
    "In VS Code - you can click \"Run All\" in the topbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "! pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Set up the Gemini API client\n",
    "# Replace '<your_api_key>' with your actual Google AI API key\n",
    "genai.configure(api_key='<your_api_key>')\n",
    "\n",
    "system_prompt = \"You are an AI assistant monitoring database performance. When you receive an alert, gather diagnostic information and generate commands to optimize the database. Send only 1 command that I should run and send only the command with no comments before or after.\"\n",
    "\n",
    "# Set up the model\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-pro\", system_instruction=system_prompt)\n",
    "\n",
    "alert = \"Slow query performance detected on database-01. Average query time: 2.5 seconds\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [f\"Alert: {alert}\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = model.generate_content(messages)\n",
    "\n",
    "print(\"Diagnostic commands:\")\n",
    "print(response.text)\n",
    "\n",
    "# Simulate running the diagnostic commands\n",
    "diagnostic_results = \"\"\"\n",
    "Top 5 slow queries:\n",
    "1. SELECT * FROM orders WHERE date > '2023-01-01' (avg time: 3.2s)\n",
    "2. SELECT customers.*, orders.* FROM customers JOIN orders ON customers.id = orders.customer_id (avg time: 2.8s)\n",
    "3. UPDATE inventory SET stock = stock - 1 WHERE product_id IN (SELECT product_id FROM order_items WHERE order_id = 12345) (avg time: 2.5s)\n",
    "4. SELECT COUNT(*) FROM log_entries WHERE timestamp > NOW() - INTERVAL 1 DAY (avg time: 2.3s)\n",
    "5. DELETE FROM expired_sessions WHERE last_activity < NOW() - INTERVAL 30 DAY (avg time: 2.1s)\n",
    "\n",
    "Current database stats:\n",
    "- Buffer pool hit ratio: 85%\n",
    "- Index usage: 70%\n",
    "- Table scans: 25% of queries\n",
    "- Temporary tables created on disk: 15% of queries\n",
    "\"\"\"\n",
    "\n",
    "# Add the diagnostic results to the messages\n",
    "messages.append({\n",
    "    \"role\": \"model\",\n",
    "    \"parts\": [response.text]\n",
    "})\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": [diagnostic_results]\n",
    "})\n",
    "\n",
    "# Get optimization commands from the LLM\n",
    "response = model.generate_content(messages)\n",
    "\n",
    "print(\"\\nOptimization commands:\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
